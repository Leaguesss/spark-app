{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Sentence Vector Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from file and transform the data such that \"sentence1\" and \"sentence2\" merged into the same column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genre: string (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_path = 'MNLI/train.tsv'\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"training explore\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "train = spark.read.csv(training_path,header=True,sep='\\t') \\\n",
    "                        .select(\"genre\", \"sentence1\", \"sentence2\") \\\n",
    "                        .fillna(\"\")\n",
    "\n",
    "genre_sentence = train.rdd.flatMap(lambda line: [(line[0],line[1]),(line[0],line[2])]).cache()\n",
    "genre_sentence_df = spark.createDataFrame(genre_sentence, [\"genre\",\"sentence\"])\n",
    "\n",
    "genre_sentence_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find TF-IDF based vector representation\n",
    "\n",
    "#### Create pipeline for the transformation from sentence to TF-IDF vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDimention = 20\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(numFeatures=numDimention, inputCol=\"words\", outputCol=\"TF\")\n",
    "idf = IDF(inputCol=\"TF\", outputCol=\"TF-IDF\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the sentences to vector with the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|     genre|              TF-IDF|\n",
      "+----------+--------------------+\n",
      "|government|(20,[0,4,5,6,8,13...|\n",
      "|government|(20,[4,5,6,11,13,...|\n",
      "| telephone|(20,[0,1,2,3,4,5,...|\n",
      "+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TFIDF = pipeline.fit(genre_sentence_df.select(\"sentence\")) \\\n",
    "                    .transform(genre_sentence_df) \\\n",
    "                    .select(\"genre\", \"TF-IDF\")\n",
    "\n",
    "TFIDF.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function which encodes partition of sentences to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_embed(rev_text_partition):\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "    embed = hub.Module(module_url)\n",
    "    # mapPartition would supply element inside a partition using generator stype\n",
    "    # this does not fit tensorflow stype\n",
    "    rev_text_list = [text[1] for text in rev_text_partition]\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "#         message_embeddings = session.run(embed([rev_text_partition]))\n",
    "        message_embeddings = session.run(embed(rev_text_list))\n",
    "    return message_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (limit to 1000 for single node testing)\n",
    "#### Transformation to get  the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "encoding = genre_sentence_df.limit(1000) \\\n",
    "                            .rdd \\\n",
    "                            .mapPartitions(review_embed) \\\n",
    "                            .map(lambda line:Vectors.dense(line)).cache()\n",
    "\n",
    "genre_encoding = genre_sentence_df.limit(1000).select(\"genre\").rdd.map(lambda x:x['genre']).zip(encoding)\n",
    "encoding.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Clustering for Universal Encoder by first reducing the dimention with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=15, inputCol=\"features\", outputCol=\"pca\")\n",
    "test_vectors = genre_encoding.toDF([\"genre\",\"features\"])\n",
    "model = pca.fit(test_vectors)\n",
    "pca_result = model.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(featuresCol='pca',k=5)\n",
    "km_model = kmeans.fit(pca_result)\n",
    "prediction_universal = km_model.transform(pca_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Clustering for TF-IDF Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(featuresCol='TF-IDF',k=5)\n",
    "model = kmeans.fit(TFIDF)\n",
    "predictions = model.transform(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=0),\n",
       " Row(prediction=0),\n",
       " Row(prediction=3),\n",
       " Row(prediction=0),\n",
       " Row(prediction=0),\n",
       " Row(prediction=2),\n",
       " Row(prediction=0),\n",
       " Row(prediction=0),\n",
       " Row(prediction=4),\n",
       " Row(prediction=2)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.select('prediction').take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
