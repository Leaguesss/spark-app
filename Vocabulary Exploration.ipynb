{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType,IntegerType, FloatType\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_paths = ['MNLI/dev_matched.tsv', 'MNLI/test_matched.tsv']\n",
    "mismatch_paths = ['MNLI/dev_mismatched.tsv', 'MNLI/test_mismatched.tsv']\n",
    "training_path = 'MNLI/train.tsv'\n",
    "stop_words_path = 'MNLI/stopwords.txt'\n",
    "remote_path = 's3://qsftw-bucket/COMP5349/dev_matched.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- promptID: string (nullable = true)\n",
      " |-- pairID: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- sentence1_binary_parse: string (nullable = true)\n",
      " |-- sentence2_binary_parse: string (nullable = true)\n",
      " |-- sentence1_parse: string (nullable = true)\n",
      " |-- sentence2_parse: string (nullable = true)\n",
      " |-- sentence1: string (nullable = true)\n",
      " |-- sentence2: string (nullable = true)\n",
      " |-- label1: string (nullable = true)\n",
      " |-- label2: string (nullable = true)\n",
      " |-- label3: string (nullable = true)\n",
      " |-- label4: string (nullable = true)\n",
      " |-- label5: string (nullable = true)\n",
      " |-- gold_label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"training explore\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "match = spark.read.csv(match_paths,header=True,sep='\\t')\n",
    "mismatch = spark.read.csv(mismatch_paths,header=True,sep='\\t')\n",
    "match.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_sentences = match.select(\"sentence1\", \"sentence2\").rdd.map(list)\n",
    "\n",
    "mismatch_sentences = mismatch.select(\"sentence1\", \"sentence2\").rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatSentence(line):\n",
    "    '''\n",
    "    Concatenate sentence1 and sentence2 and get the words in the \n",
    "    two sentences and return as a list of words. Basic preprocessing\n",
    "    including remove empty string and convert to lowercase is done.\n",
    "    '''\n",
    "    line1 = line[0] if line[0] != None else \"\"\n",
    "    line2 = line[1] if line[1] != None else \"\"\n",
    "    concat = line1 + \" \" + line2\n",
    "    wordList = concat.lower().split(' ')\n",
    "    processedWordList = []\n",
    "    for word in wordList:\n",
    "        if word != '':\n",
    "            processedWordList.append(word.strip())   \n",
    "    return processedWordList\n",
    "\n",
    "match_words = match_sentences \\\n",
    "                .flatMap(concatSentence) \\\n",
    "                .distinct().map(lambda word:(word,1)) \\\n",
    "                .cache()\n",
    "\n",
    "mismatch_words = mismatch_sentences \\\n",
    "                    .flatMap(concatSentence) \\\n",
    "                    .distinct() \\\n",
    "                    .map(lambda word:(word,1)) \\\n",
    "                    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Common Words:\t13000\n",
      "Number of Unique Matched Words:\t18592\n",
      "Number of Unique Mismatched Words:\t15826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_words_count = match_words.join(mismatch_words).count()\n",
    "unique_matches_count = match_words.subtractByKey(mismatch_words).count()\n",
    "unique_mismatches_count = mismatch_words.subtractByKey(match_words).count()\n",
    "\n",
    "print(\"Number of Common Words:\\t\" + str(common_words_count) + '\\n' + \\\n",
    "     \"Number of Unique Matched Words:\\t\" + str(unique_matches_count) + '\\n' + \\\n",
    "     \"Number of Unique Mismatched Words:\\t\" + str(unique_mismatches_count) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv(training_path,header=True,sep='\\t')\n",
    "train_sentences = train.select(\"genre\", \"sentence1\", \"sentence2\").rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGenreWordPair(line):\n",
    "    wordList = concatSentence([line[1],line[2]])\n",
    "    return [(word, line[0]) for word in wordList]\n",
    "\n",
    "word_genre_pair = train_sentences.flatMap(makeGenreWordPair)\n",
    "\n",
    "words_genreSet_pair = word_genre_pair \\\n",
    "                        .groupByKey() \\\n",
    "                        .mapValues(set) \\\n",
    "                        .cache()\n",
    "\n",
    "num_genre_num_words_pair = words_genreSet_pair \\\n",
    "                            .map(lambda line: (len(line[1]), line[0])) \\\n",
    "                            .groupByKey() \\\n",
    "                            .mapValues(len) \\\n",
    "                            .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of words in 1genre(s): \t0.6880971408805181\n",
      "Percentage of words in 2genre(s): \t0.1308849314741701\n",
      "Percentage of words in 3genre(s): \t0.07043429512029295\n",
      "Percentage of words in 4genre(s): \t0.049942149647530326\n",
      "Percentage of words in 5genre(s): \t0.06064148287748846\n"
     ]
    }
   ],
   "source": [
    "def showPercentages(result):\n",
    "    total_words = 0\n",
    "    for pair in result:\n",
    "        total_words += pair[1]\n",
    "    for pair in sorted(num_genre_num_words_pair):\n",
    "        print(\"Percentage of words in \" + str(pair[0]) + 'genre(s): \\t' + str(pair[1]/total_words))\n",
    "showPercentages(num_genre_num_words_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of words in 1genre(s): \t0.6890217319900388\n",
      "Percentage of words in 2genre(s): \t0.13106080060197434\n",
      "Percentage of words in 3genre(s): \t0.07052893716892905\n",
      "Percentage of words in 4genre(s): \t0.050009256549755444\n",
      "Percentage of words in 5genre(s): \t0.060722966395738404\n"
     ]
    }
   ],
   "source": [
    "stopwords = []\n",
    "with open(stop_words_path) as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "spark.sparkContext.broadcast(stopwords)\n",
    "\n",
    "words_genreSet_pair_stopwords = words_genreSet_pair.filter(lambda line: line[0] not in stopwords)\n",
    "num_genre_num_words_pair_stopwords = words_genreSet_pair_stopwords \\\n",
    "                                        .map(lambda line: (len(line[1]), line[0])) \\\n",
    "                                        .groupByKey() \\\n",
    "                                        .mapValues(len) \\\n",
    "                                        .collect()\n",
    "\n",
    "showPercentages(num_genre_num_words_pair_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 8374), (5, 10168), (1, 115376), (2, 21946), (3, 11810)]\n",
      "[(4, 8360), (5, 9995), (1, 115362), (2, 21936), (3, 11796)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
